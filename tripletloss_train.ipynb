{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletImageDataset(Dataset):\n",
    "    def __init__(self, image_data, labels, transform=None, num_triplets=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_data (torch.Tensor): A tensor of shape (N, 1, 128, 128) containing the images.\n",
    "            labels (torch.Tensor): A tensor of shape (N,) containing the labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            num_triplets (int, optional): Number of triplets to generate. If None, generates all possible triplets.\n",
    "        \"\"\"\n",
    "        self.image_data = torch.tensor(image_data, dtype=torch.float32).repeat(1, 3, 1, 1)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "        self.num_triplets = num_triplets if num_triplets else self.image_data.size(0)\n",
    "\n",
    "        # Generate triplets\n",
    "        self.triplets = self._generate_triplets(num_triplets)\n",
    "\n",
    "    def _generate_triplets(self, num_triplets):\n",
    "        triplets = []\n",
    "        unique_labels = torch.unique(self.labels).tolist()\n",
    "        \n",
    "        for _ in range(num_triplets):\n",
    "            label1, label2 = random.sample(unique_labels, 2)\n",
    "            positive_indices = torch.where(self.labels == label1)[0].tolist()\n",
    "            negative_indices = torch.where(self.labels == label2)[0].tolist()\n",
    "\n",
    "            anchor, positive = random.sample(positive_indices, 2)\n",
    "            negative = random.choice(negative_indices)\n",
    "            triplets.append((anchor, positive, negative))\n",
    "\n",
    "        return triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_idx, positive_idx, negative_idx = self.triplets[idx]\n",
    "\n",
    "        anchor = self.image_data[anchor_idx]\n",
    "        positive = self.image_data[positive_idx]\n",
    "        negative = self.image_data[negative_idx]\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "    \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_data (torch.Tensor): A tensor of shape (N, 1, 128, 128) containing the images.\n",
    "            labels (torch.Tensor): A tensor of shape (N,) containing the labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_data = torch.tensor(image_data, dtype = torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_data[idx]  # Shape: (1, 128, 128)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Convert single-channel image to 3-channel by copying the channel\n",
    "        image = image.repeat(3, 1, 1)  # Shape: (3, 128, 128)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class RandomRotation:\n",
    "    def __init__(self, degrees, p=0.5):\n",
    "        self.degrees = degrees\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            angle = random.uniform(-self.degrees, self.degrees)\n",
    "            img = F.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "class RandomGaussianBlur:\n",
    "    def __init__(self, kernel_size, sigma=(0.1, 2.0), p=0.5):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            img = F.gaussian_blur(img, self.kernel_size, self.sigma)\n",
    "        return img\n",
    "\n",
    "class RandomNoise:\n",
    "    def __init__(self, mean=0, std=0.1, p=0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            noise = torch.randn_like(img) * self.std + self.mean\n",
    "            img = img + noise\n",
    "            img = torch.clamp(img, 0, 1)  # Clamp values to [0, 1] range\n",
    "        return img\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    RandomRotation(degrees=30, p=0.5),\n",
    "])\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, margin: float = None): \n",
    "    \"\"\"\n",
    "    Computes Triplet Loss with a dynamic margin if not provided.\n",
    "    \"\"\"\n",
    "    # Compute distances\n",
    "    distance_positive = torch.norm(anchor - positive, p=2, dim=1)\n",
    "    distance_negative = torch.norm(anchor - negative, p=2, dim=1)\n",
    "    \n",
    "    # Default margin selection based on statistics\n",
    "    mean_pos, std_pos = distance_positive.mean(), distance_positive.std()\n",
    "    mean_neg, std_neg = distance_negative.mean(), distance_negative.std()\n",
    "    \n",
    "    margin = (mean_neg - mean_pos) - (std_pos + std_neg)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = torch.clamp(distance_positive - distance_negative + margin, min=0.0)\n",
    "    return torch.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MONSTER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\MONSTER\\AppData\\Local\\Temp\\ipykernel_22920\\4250414041.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50.load_state_dict(torch.load(\"models/resnet50_basemodel.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.1628\n",
      "Epoch [1/100], Test Loss: 0.1251, Unseen Data Accuracy: 0.5300\n",
      "\n",
      "Epoch [2/100], Train Loss: 0.1667\n",
      "Epoch [2/100], Test Loss: 0.1235, Unseen Data Accuracy: 0.5550\n",
      "\n",
      "Epoch [3/100], Train Loss: 0.1558\n",
      "Epoch [3/100], Test Loss: 0.1452, Unseen Data Accuracy: 0.5150\n",
      "\n",
      "Epoch [4/100], Train Loss: 0.1406\n",
      "Epoch [4/100], Test Loss: 0.1285, Unseen Data Accuracy: 0.5100\n",
      "\n",
      "Epoch [5/100], Train Loss: 0.1264\n",
      "Epoch [5/100], Test Loss: 0.1221, Unseen Data Accuracy: 0.4850\n",
      "\n",
      "Epoch [6/100], Train Loss: 0.1397\n",
      "Epoch [6/100], Test Loss: 0.1400, Unseen Data Accuracy: 0.5500\n",
      "\n",
      "Epoch [7/100], Train Loss: 0.1469\n",
      "Epoch [7/100], Test Loss: 0.1339, Unseen Data Accuracy: 0.5500\n",
      "\n",
      "Epoch [8/100], Train Loss: 0.1592\n",
      "Epoch [8/100], Test Loss: 0.1261, Unseen Data Accuracy: 0.5400\n",
      "\n",
      "Epoch [9/100], Train Loss: 0.1732\n",
      "Epoch [9/100], Test Loss: 0.1236, Unseen Data Accuracy: 0.5450\n",
      "\n",
      "Epoch [10/100], Train Loss: 0.1547\n",
      "Epoch [10/100], Test Loss: 0.1426, Unseen Data Accuracy: 0.5150\n",
      "\n",
      "Early stopping triggered\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights = False)\n",
    "\n",
    "resnet50 = torch.nn.Sequential(*list(model.children())[:-1], nn.Flatten(), nn.Linear(2048, 100))\n",
    "resnet50.load_state_dict(torch.load(\"models/resnet50_basemodel.pth\"))\n",
    "\n",
    "resnet50 = resnet50[:-1]\n",
    "\n",
    "# Load data\n",
    "train_data = np.load(\"data/train.npz\")\n",
    "test_data = np.load(\"data/test.npz\")\n",
    "unseen_test_data = np.load(\"data/test_unseen.npz\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TripletImageDataset(train_data[\"data\"], train_data[\"labels\"], transform=transform, num_triplets = 1000)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TripletImageDataset(test_data[\"data\"], test_data[\"labels\"], transform=transform, num_triplets=1000)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "unseen_test_dataset = ImageDataset(unseen_test_data[\"data\"], unseen_test_data[\"labels\"], transform=transform)\n",
    "unseen_test_dataloader = DataLoader(unseen_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = triplet_loss  # For classification tasks\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=1e-7)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50.to(device)  # Move model to GPU if available\n",
    "\n",
    "train_losses = list()\n",
    "test_losses = list()\n",
    "test_accs = list()\n",
    "unseen_test_accs = list()\n",
    "\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    resnet50.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    batch = 0\n",
    "    for anchor, positive, negative in train_dataloader:\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        anchor_embedding, pos_embedding, neg_embedding = resnet50(anchor), resnet50(positive), resnet50(negative)\n",
    "        loss = criterion(anchor_embedding, pos_embedding, neg_embedding, batch)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item() * anchor.size(0)\n",
    "        batch += 1\n",
    "\n",
    "\n",
    "    # Calculate training loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    resnet50.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for anchor, positive, negative in test_dataloader:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            anchor_embedding, pos_embedding, neg_embedding = resnet50(anchor), resnet50(positive), resnet50(negative)\n",
    "            loss = criterion(anchor_embedding, pos_embedding, neg_embedding, batch)\n",
    "\n",
    "            # Accumulate test loss\n",
    "            test_loss += loss.item() * anchor.size(0)\n",
    "            \n",
    "    \n",
    "    all_embeds = []\n",
    "    unseen_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in unseen_test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            embeds = resnet50(inputs)\n",
    "\n",
    "            all_embeds.append(embeds)\n",
    "            unseen_labels.append(labels)\n",
    "\n",
    "    all_embeds = torch.cat(all_embeds)\n",
    "    unseen_labels = torch.cat(unseen_labels)\n",
    "\n",
    "    distances = torch.cdist(all_embeds, all_embeds)\n",
    "\n",
    "    correct_pred = 0\n",
    "    for i in range(all_embeds.size(0)):\n",
    "        distances[i,i] = float(\"inf\")\n",
    "        closest_inx = distances[i].argmin()\n",
    "        if unseen_labels[i] == unseen_labels[closest_inx]:\n",
    "            correct_pred += 1\n",
    "\n",
    "    unseen_test_accuracy = correct_pred / all_embeds.size(0)\n",
    "\n",
    "\n",
    "    # Calculate test loss and accuracy\n",
    "    test_loss = test_loss / len(test_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss:.4f}, Unseen Data Accuracy: {unseen_test_accuracy:.4f}\")\n",
    "    print()\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    unseen_test_accs.append(unseen_test_accuracy)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(resnet50.state_dict(), \"models/resnet50_triplet.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(resnet50.state_dict(), \"models/resnet50_triplet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train loss\")\n",
    "plt.plot(test_losses, label=\"Test loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and Test loss during training.\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_accs, label=\"Train loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Test accuracy during training.\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
