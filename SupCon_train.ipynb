{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_data, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_data (torch.Tensor): A tensor of shape (N, 1, 128, 128) containing the images.\n",
    "            labels (torch.Tensor): A tensor of shape (N,) containing the labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_data = torch.tensor(image_data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.image_data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = image.repeat(3, 1, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented_image = self.transform(image)\n",
    "            return image, augmented_image, label\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "class RandomRotation:\n",
    "    def __init__(self, degrees, p=0.5):\n",
    "        self.degrees = degrees\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            angle = random.uniform(-self.degrees, self.degrees)\n",
    "            img = F.rotate(img, angle)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    RandomRotation(degrees=30, p=1.0),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, base_temperature=0.07):\n",
    "        \"\"\"\n",
    "        Implementation of Supervised Contrastive Learning loss\n",
    "        \n",
    "        Args:\n",
    "            temperature: Scaling parameter for cosine similarity\n",
    "            base_temperature: Baseline temperature parameter\n",
    "        \"\"\"\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: Hidden vector of shape [batch_size, n_views, ...].\n",
    "            labels: Ground truth of shape [batch_size].\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        batch_size = features.shape[0]\n",
    "        \n",
    "        # Reshape features to [batch_size * n_views, ...]\n",
    "        if len(features.shape) < 3:\n",
    "            features = features.unsqueeze(1)\n",
    "        features = features.view(features.shape[0], features.shape[1], -1)\n",
    "        n_views = features.shape[1]\n",
    "        features = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        \n",
    "        # Expand labels to match features\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        labels = labels.repeat(n_views, 1)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        features = nn.functional.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        \n",
    "        # Get mask for positive pairs\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        \n",
    "        # For numerical stability\n",
    "        logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "        logits = similarity_matrix - logits_max.detach()\n",
    "        \n",
    "        # Compute log_prob\n",
    "        exp_logits = torch.exp(logits / self.temperature)\n",
    "        log_prob = logits / self.temperature - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "        \n",
    "        # Compute mean of log-likelihood over positive pairs\n",
    "        mask_pos = mask.clone()\n",
    "        mask_pos[torch.eye(mask_pos.shape[0], dtype=torch.bool).to(device)] = 0\n",
    "        mean_log_prob_pos = (mask_pos * log_prob).sum(1) / mask_pos.sum(1)\n",
    "        \n",
    "        # Loss\n",
    "        loss = -(self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.mean()\n",
    "        \n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights = False)\n",
    "\n",
    "resnet50 = torch.nn.Sequential(*list(model.children())[:-1], nn.Flatten(), nn.Linear(2048, 100))\n",
    "resnet50.load_state_dict(torch.load(\"models/resnet50_basemodel.pth\"))\n",
    "\n",
    "resnet50 = resnet50[:-1]\n",
    "\n",
    "# Load data\n",
    "train_data = np.load(\"data/train.npz\")\n",
    "test_data = np.load(\"data/test.npz\")\n",
    "unseen_test_data = np.load(\"data/test_unseen.npz\")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ImageDataset(train_data[\"data\"], train_data[\"labels\"], transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = ImageDataset(test_data[\"data\"], test_data[\"labels\"], transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "unseen_test_dataset = ImageDataset(unseen_test_data[\"data\"], unseen_test_data[\"labels\"])\n",
    "unseen_test_dataloader = DataLoader(unseen_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = SupConLoss()  # For classification tasks\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50.to(device)  # Move model to GPU if available\n",
    "\n",
    "train_losses = list()\n",
    "test_losses = list()\n",
    "test_accs = list()\n",
    "unseen_test_accs = list()\n",
    "\n",
    "patience = 5\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    resnet50.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    batch = 0\n",
    "    for anchors, augmented, labels in train_dataloader:\n",
    "        inputs = torch.cat([anchors, augmented]).to(device)\n",
    "        labels = torch.cat([labels, labels]).to(device)\n",
    "        \n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings = resnet50(inputs)\n",
    "        loss = criterion(embeddings, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        batch += 1\n",
    "\n",
    "\n",
    "    # Calculate training loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    resnet50.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for anchors, augmented, labels in train_dataloader:\n",
    "            inputs = torch.cat([anchors, augmented]).to(device)\n",
    "            labels = torch.cat([labels, labels]).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            embeddings = resnet50(inputs)\n",
    "            loss = criterion(embeddings, labels)\n",
    "\n",
    "            # Accumulate test loss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "    \n",
    "    all_embeds = []\n",
    "    unseen_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in unseen_test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            embeds = resnet50(inputs)\n",
    "\n",
    "            all_embeds.append(embeds)\n",
    "            unseen_labels.append(labels)\n",
    "\n",
    "    all_embeds = torch.cat(all_embeds)\n",
    "    unseen_labels = torch.cat(unseen_labels)\n",
    "\n",
    "    distances = torch.cdist(all_embeds, all_embeds)\n",
    "\n",
    "    correct_pred = 0\n",
    "    for i in range(all_embeds.size(0)):\n",
    "        distances[i,i] = float(\"inf\")\n",
    "        closest_inx = distances[i].argmin()\n",
    "        if unseen_labels[i] == unseen_labels[closest_inx]:\n",
    "            correct_pred += 1\n",
    "\n",
    "    unseen_test_accuracy = correct_pred / all_embeds.size(0)\n",
    "\n",
    "\n",
    "    # Calculate test loss and accuracy\n",
    "    test_loss = test_loss / len(test_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Test Loss: {test_loss:.4f}, Unseen Data Accuracy: {unseen_test_accuracy:.4f}\")\n",
    "    print()\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    unseen_test_accs.append(unseen_test_accuracy)\n",
    "\n",
    "    # Check for early stopping\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(resnet50.state_dict(), \"models/resnet50_fintune_100_256.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50, \"models/resnet50_triplet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train loss\")\n",
    "plt.plot(test_losses, label=\"Test loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train and Test loss during training.\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_accs, label=\"Train loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Test accuracy during training.\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
